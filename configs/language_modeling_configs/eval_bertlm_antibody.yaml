defaults:
    - logger_cfgs: Tensorboard
    #- hydra/launcher: submitit_slurm

experiment_name: "eval_bertlm_heavychain"
nodes: 1
reload_checkpoint_path: <Full Path>/HC.ckpt

hydra:
    run:
        dir: ./results/eval/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

model_cfg: 
    _target_: src.models.BertForMaskedLanguageModeling
    model_type: transformer
    task: masked_language_modeling
    model_config_file: <Full Path>/biotransfer/pretrained_models/bert_configs/config.json
    lr: 1e-5
    warmup_steps: 10000
    
trainer_cfg:
    gpus: 2
    num_nodes: ${nodes}
    distributed_backend: ddp


eval_set_cfg:
    _target_: src.datasets.AntibodyLanguageModelingDataset
    data_path: <Full Path>/oas_heavy_test.lmdb
    tokenizer: "iupac"
    in_memory: False
    maxlen: 512
    
eval_dataloader_cfg:
    batch_size: 32
