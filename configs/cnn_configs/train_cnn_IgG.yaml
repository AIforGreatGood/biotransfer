defaults:
    - model_cfg: CNN
    - logger_cfgs: Tensorboard
    #- override hydra/launcher: submitit_slurm

experiment_name: train_cnn_IgG

hydra:
    run:
        dir: ./results/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
##########

trainer_cfg:
    max_epochs: 5000
    gpus: 2
    num_nodes: 1
    distributed_backend: ddp

train_set_cfg:
    _target_: src.datasets.GiffordDataset
    data_path: /home/li25662/AIforGreatGood/biotransfer/data/IgG/rep1_rep2_splits
    split: train
    in_memory: False
    collate_type: full_padded
    token_encode_type: one_hot
    
train_dataloader_cfg:
    batch_size: 32
    shuffle: True

callback_cfgs:
    early_stopping:
        _target_: pytorch_lightning.callbacks.EarlyStopping
        monitor: val_loss
        verbose: True
        patience: 20
        
checkpoint_callback_cfg:
    filepath: checkpoint/
    
val_set_cfg:
    _target_: ${train_set_cfg._target_}
    data_path: ${train_set_cfg.data_path}
    split: val
    in_memory: ${train_set_cfg.in_memory}
    collate_type: ${train_set_cfg.collate_type}
    token_encode_type: ${train_set_cfg.token_encode_type}
    
val_dataloader_cfg:
    batch_size: ${train_dataloader_cfg.batch_size}
