defaults:
    - logger_cfgs: Tensorboard
    #- override hydra/launcher: submitit_slurm

experiment_name: "train_finetune_IgG"
nodes: 1
strict_reload: False
reload_checkpoint_path: "/home/gridsan/groups/ai4bio_shared/models/in_house/pfam_batchsize_2048_layers_24_lr_1e-5_hidsize_1024_intermediatesize_4096_attentionheads_16_epoch_13.ckpt"

hydra:
    run:
        dir: ./results/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
############

model_cfg:
    _target_: src.models.BertForValuePrediction
    downstream_dropout: 0.1
    downstream_hid_dim: 512
    lr: 2.79551209035589e-05
    loss_function: mse
    model_config_file: /home/gridsan/groups/ai4bio_shared/models/in_house/bert_configs/bert/config.json
    warmup_steps: 10000

trainer_cfg:
    max_epochs: 5000
    gpus: 2
    num_nodes: ${nodes}
    distributed_backend: ddp

train_set_cfg:
    _target_: src.datasets.GiffordDataset
    data_path: "/home/gridsan/groups/ai4bio_shared/datasets/gifford/rep1_rep2_splits"
    split: train
    
train_dataloader_cfg:
    batch_size: 32
    shuffle: True

callback_cfgs:
    early_stopping:
        _target_: pytorch_lightning.callbacks.EarlyStopping
        monitor: val_loss
        verbose: True
        patience: 20
        
checkpoint_callback_cfg:
    filepath: "checkpoint/"
    
val_set_cfg:
    _target_: src.datasets.GiffordDataset
    data_path: "/home/gridsan/groups/ai4bio_shared/datasets/gifford/rep1_rep2_splits"
    split: test
    
val_dataloader_cfg:
    batch_size: 32

