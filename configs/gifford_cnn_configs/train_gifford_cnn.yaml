defaults:
    - model_cfg: GiffordCNN
    - logger_cfgs: Tensorboard
#    - hydra/sweeper: ax
    - override hydra/launcher: submitit_slurm
#    - override hydra/sweeper: optuna

experiment_name: GiffordCNN_train
#strict_reload: False
#reload_checkpoint_path: "/home/gridsan/LI25662/ai4bio_shared/models/in_house/heavychain_initialized_by_pfam_batchsize_2048_layers_24_lr_1e-5_hidsize_1024_intermediatesize_4096_attentionheads_16_epoch_5.ckpt"

hydra:
    run:
        dir: ./results/train/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

    sweep:
        dir: ./results/train/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    
    
    #sweeper:
        #optuna_config:
          #direction: minimize
          #study_name: ${experiment_name}
          #storage: postgresql://pguser:y26j59ayacu09bbwlrgrjfbcg@txg-optape.cloud.llgrid.ll.mit.edu/postgres
          #n_trials: 30
          #n_jobs: 1
          #sampler: random
        #search_space:
          #model_cfg.lr:
            #type: float
            #low: 1e-6
            #high: 1e-4
            #log: true
          #model_cfg.downstream_dropout:
            #type: categorical
            #choices:
              #- 0.0
              #- 0.1
              #- 0.2
              #- 0.3
              #- 0.4
              #- 0.5
          #model_cfg.downstream_hid_dim:
            #type: categorical
            #choices:
              #- 128
              #- 256
              #- 512
              #- 1024

    launcher:
        partition: gaia
        tasks_per_node: 2
        nodes: ${trainer_cfg.num_nodes}
        constraint: xeon-g6
        timeout_min: 10000
        additional_parameters:
            {'gres':'gpu:volta:2'}
############

trainer_cfg:
    max_epochs: 20
    gpus: 2
    num_nodes: 8
    distributed_backend: ddp

train_set_cfg:
    _target_: src.datasets.GiffordDataset
    data_path: /home/gridsan/groups2/ai4bio_shared/datasets/gifford/rep1_rep2_splits/
    split: train
    in_memory: False
    collate_type: full_padded
    token_encode_type: one_hot
    
train_dataloader_cfg:
    batch_size: 32
    shuffle: True

callback_cfgs:
    early_stopping:
        _target_: pytorch_lightning.callbacks.EarlyStopping
        monitor: val_loss
        verbose: True
        
checkpoint_callback_cfg:
    filepath: checkpoint/
    
val_set_cfg:
    _target_: ${train_set_cfg._target_}
    data_path: ${train_set_cfg.data_path}
    split: val
    in_memory: ${train_set_cfg.in_memory}
    collate_type: ${train_set_cfg.collate_type}
    token_encode_type: ${train_set_cfg.token_encode_type}
    
val_dataloader_cfg:
    batch_size: ${train_dataloader_cfg.batch_size}
